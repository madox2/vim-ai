[default]
options.token_file_path = /custom/path/ai.token

[test-role-simple]
prompt = simple role prompt
options.model = o1-preview

[test-role]
options.model = model-common
ui.paste_mode = 0
[test-role.chat]
options.endpoint_url = https://localhost/chat
ui.open_chat_command = preset_tab
[test-role.complete]
options.endpoint_url = https://localhost/complete
[test-role.edit]
options.endpoint_url = https://localhost/edit

[chat-only-role.chat]
options.open_chat_command = preset_tab

[hd-image.image]
options.quality = hd

[deprecated-test-role-simple]
prompt = simple role prompt
[deprecated-test-role-simple.options]
model = o1-preview

[deprecated-test-role]
[deprecated-test-role.options]
model = model-common
[deprecated-test-role.options-chat]
endpoint_url = https://localhost/chat
[deprecated-test-role.options-complete]
endpoint_url = https://localhost/complete
[deprecated-test-role.options-edit]
endpoint_url = https://localhost/edit
[deprecated-test-role.ui]
paste_mode = 0
[deprecated-test-role.ui-chat]
open_chat_command = preset_tab

[all_params.chat]
options.frequency_penalty = 0.5
options.logit_bias = {"2435": -100}
options.logprobs = 1
options.presence_penalty = -0.5
options.reasoning_effort = low
options.seed = 12345
options.stop = stop_sequence
options.top_logprobs = 5
options.top_p = 0.9

[test-role-openrouter-reasoning]
options.reasoning = {"effort": "high", "max_tokens": "2000", "exclude": "0", "enabled": "1"}
